# EORA LLM Service с использованием GigaChat и FastAPI

---

## Описание

Этот проект реализует сервис на FastAPI, который обрабатывает запросы и отвечает с помощью модели GigaChat от Сбера.  
Для удобства сервис упакован в Docker-контейнер и управляется через Docker Compose.

---

## Функционал

- Эндпоинт `/answer`, принимающий POST запрос с вопросом.
- Асинхронное обращение к GigaChat API через асинхронный клиент `GigaChatAsyncClient` и метод `achat`.
- Добавление релевантных ссылок на кейсы из материалов EORA, если вопрос содержит ключевое слово `ритейлер`.
- Простая и расширяемая архитектура.

---

## Установка и запуск

### Локальный запуск (без Docker)

1. Клонируйте репозиторий или скачайте код.

2. Создайте и активируйте виртуальное окружение (рекомендуется):

```bash
python -m venv venv
source venv/bin/activate # macOS/Linux
venv\Scripts\activate # Windows
```

3. Установите зависимости:
```bash
pip install -r requirements.txt
```

4. Создайте файл `.env` в корне проекта и задайте в нем ваш ключ GigaChat API:

```bash
GIGA_CHAT_KEY=ваш_ключ_GigaChat_без_кавычек
```

5. Запустите FastAPI сервер:

```bash
uvicorn app.main:app --reload
```

6. Перейдите в браузере по адресу:  
```bash
http://127.0.0.1:8000/docs
```
Там находится Swagger UI — удобный интерфейс для тестирования API.

---
### Запуск через Docker (рекомендуется)

1. Убедитесь, что на вашей машине установлены Docker и Docker Compose.

2. Проверьте, что в корне проекта есть файл `.env` с вашим GigaChat ключом

3. Соберите Docker-образ:
```bash
docker-compose build
```

4. Запустите контейнер:
```bash
docker-compose up
```
5. Перейдите в браузере по адресу:  
```bash
http://localhost:8000/docs
```

---

Если вы вносите изменения в код и хотите пересобрать образ с запуском:
```bash
docker-compose up --build
```




## Пример запроса

POST `/answer`

Тело запроса (application/json):

```bash
{
  "question": "Что вы можете сделать для ритейлеров?"
}
```

---

## Пример ответа


```bash
{
    "answer": "EORA предлагает решения для ритейлеров с помощью ИИ: чат-боты для HR, визуальный поиск товаров по фото и автоматизация контакт-центров.",
    "sources": [
        "https://eora.ru/cases/chat-boty/hr-bot-dlya-magnit-kotoriy-priglashaet-na-sobesedovanie",
        "https://eora.ru/cases/kazanexpress-poisk-tovarov-po-foto"
    ]
}
```


---

## Используемые технологии

- Python 3.11+
- FastAPI — веб-фреймворк для API
- GigaChat Python SDK (`gigachat`) с использованием асинхронного клиента `GigaChatAsyncClient`
- Pydantic-settings — для загрузки настроек из `.env`
- Uvicorn — ASGI-сервер для запуска FastAPI приложения

---

## Описание хода разработки

1. Начал с выбора обёртки для сервиса. Выбор пал на написание простенького API на FastAPI
2. В ходе разработки столкнулся с проблемой кэширования встроенного docs, что вызвало желание использовать Docker 
для изоляции окружения
3. Первая реализация включала в себя взаимодействие с OpenAI API, но позже было решено использовать GigaChat
в связи с проблемами с доступом, версиями библиотек и подтверждением бесплатного тарифа
4. Далее столкнулся со стандартной проблемой использования в качестве ассистента в разработке ИИ, устаревшие/выдуманные методы.
Быстро нашёл решение, залез внутрь библиотеки gigachat и нашёл необходимые методы для асинхронного обращения к API

## Возможности для дальнейшего развития проекта

- Добавить хранение и индексирование материалов компании для добавления Retrieval-Augmented Generation (RAG)
- Подключить другие языковые модели или конфигурации
- Расширить поддержку различных видов вопросов и тем
- Сделать интерфейс в Telegram, CLI или на вебе для удобства пользователей
- Добавить кеширование ответов и улучшить обработку ошибок
